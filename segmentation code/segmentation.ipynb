{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WfX8ghZLBQR",
        "outputId": "60643891-ff5a-4786-a13d-99acfada06a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading SAM checkpoint 'sam_vit_h_4b8939.pth'...\n",
            "Download complete.\n",
            "Initializing SAM model on device: cpu...\n",
            "Video opened: 1920x1080 @ 72 frames. Ready to segment.\n",
            "Generating masks frame by frame with tracking...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Segmenting Frames: 100%|██████████| 72/72 [55:06<00:00, 45.93s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Segmentation complete. Final array shape: (72, 1080, 1920)\n",
            "SUCCESS: segmentation.npz created in Colab. DOWNLOAD THIS FILE NOW.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Ensure segment_anything is installed in Colab (after torch)\n",
        "!pip install -q segment-anything\n",
        "\n",
        "# Import the necessary components\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "VIDEO_FILENAME = 'sam2Demo.mp4'\n",
        "VIDEO_PATH = f'./{VIDEO_FILENAME}'\n",
        "OUTPUT_NPZ_PATH = 'segmentation.npz'\n",
        "\n",
        "SAM_CHECKPOINT_PATH = 'sam_vit_h_4b8939.pth'\n",
        "MODEL_TYPE = 'vit_h'\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Download the checkpoint if necessary\n",
        "if os.path.exists(SAM_CHECKPOINT_PATH):\n",
        "    print(f\"Removing existing SAM checkpoint '{SAM_CHECKPOINT_PATH}' for a fresh download...\")\n",
        "    os.remove(SAM_CHECKPOINT_PATH)\n",
        "    print(\"Previous checkpoint removed.\")\n",
        "\n",
        "print(f\"Downloading SAM checkpoint '{SAM_CHECKPOINT_PATH}'...\")\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# --- CRITICAL ACTION REQUIRED: UPDATE THESE COORDINATES! ---\n",
        "# You MUST change these to the precise center of the object in Frame 0\n",
        "# Example: Use coordinates like [[350, 400]]\n",
        "INITIAL_POINT_PROMPT = np.array([[320, 420]]) \n",
        "INITIAL_POINT_LABEL = np.array([1]) # Foreground label\n",
        "\n",
        "# SPEED OPTIMIZATION\n",
        "FRAME_SKIP_COUNT = 3\n",
        "\n",
        "# FILE SIZE REDUCTION FIX: Downscale the mask significantly\n",
        "# CHANGED DOWNSCALE_FACTOR to 8 (64x reduction)\n",
        "DOWNSCALE_FACTOR = 8 \n",
        "\n",
        "# --- 1. Initialization ---\n",
        "try:\n",
        "    print(f\"Initializing SAM model on device: {DEVICE}...\")\n",
        "    sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT_PATH)\n",
        "    sam.to(device=DEVICE)\n",
        "    predictor = SamPredictor(sam)\n",
        "except Exception as e:\n",
        "    print(f\"Initialization Error: {e}. Check GPU/File download.\")\n",
        "    sys.exit()\n",
        "\n",
        "# Initialize video capture\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    print(f\"CRITICAL ERROR: Could not open video file at {VIDEO_PATH}. Ensure the name is correct.\")\n",
        "    sys.exit()\n",
        "\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) \n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "print(f\"Video opened: {frame_width}x{frame_height} @ {total_frames} frames. Ready to segment.\")\n",
        "\n",
        "# --- 2. Process Video and Generate Masks (Targeted Tracking) ---\n",
        "all_masks = []\n",
        "current_bbox = None\n",
        "\n",
        "print(\"Generating masks frame by frame with tracking...\")\n",
        "\n",
        "for i in tqdm(range(total_frames), desc=\"Segmenting Frames\"):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret: break\n",
        "\n",
        "    current_mask_to_save = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # --- Segmentation Logic (Process only key frames) ---\n",
        "    if i == 0 or (i > 0 and i % FRAME_SKIP_COUNT == 0):\n",
        "\n",
        "        predictor.set_image(rgb_frame)\n",
        "\n",
        "        # Determine the prompt: Point on frame 0, or BBOX from last frame\n",
        "        if i == 0:\n",
        "            input_points = INITIAL_POINT_PROMPT\n",
        "            input_labels = INITIAL_POINT_LABEL\n",
        "            box_prompt = None\n",
        "        elif current_bbox is not None:\n",
        "            input_points = None\n",
        "            input_labels = None\n",
        "            box_prompt = current_bbox\n",
        "        else:\n",
        "            # If tracking was lost, retry with the initial point\n",
        "            input_points = INITIAL_POINT_PROMPT\n",
        "            input_labels = INITIAL_POINT_LABEL\n",
        "            box_prompt = None\n",
        "\n",
        "        # Run SAM prediction\n",
        "        masks, scores, _ = predictor.predict(\n",
        "            point_coords=input_points,\n",
        "            point_labels=input_labels,\n",
        "            box=box_prompt,\n",
        "            multimask_output=False,\n",
        "        )\n",
        "\n",
        "        # Process the result\n",
        "        if scores[0] > 0.8: # Only accept high-confidence masks\n",
        "            current_mask_to_save = masks[0].astype(np.uint8) * 1\n",
        "\n",
        "            # Calculate the BBOX of the new mask for the next key frame's prompt\n",
        "            y_indices, x_indices = np.where(current_mask_to_save)\n",
        "            if len(x_indices) > 0:\n",
        "                # The BBOX must be calculated on the full-res mask before downscaling\n",
        "                current_bbox = np.array([\n",
        "                    np.min(x_indices), np.min(y_indices),\n",
        "                    np.max(x_indices), np.max(y_indices)\n",
        "                ])\n",
        "            else:\n",
        "                current_bbox = None\n",
        "        else:\n",
        "            current_bbox = None\n",
        "\n",
        "    else:\n",
        "        current_mask_to_save = all_masks[-1] if all_masks else np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
        "\n",
        "    # --- FILE SIZE REDUCTION HAPPENS HERE ---\n",
        "    if current_mask_to_save.any() and DOWNSCALE_FACTOR > 1:\n",
        "        # Resize to 1/8 width and 1/8 height (1/64th the size)\n",
        "        current_mask_to_save = cv2.resize(\n",
        "            current_mask_to_save, \n",
        "            (frame_width // DOWNSCALE_FACTOR, frame_height // DOWNSCALE_FACTOR), \n",
        "            interpolation=cv2.INTER_NEAREST\n",
        "        )\n",
        "\n",
        "    all_masks.append(current_mask_to_save)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# --- 3. Save the Data ---\n",
        "if all_masks:\n",
        "    final_masks_array = np.stack(all_masks, axis=0)\n",
        "    print(f\"\\nSegmentation complete. Final array shape: {final_masks_array.shape}\")\n",
        "\n",
        "    # Save the array with the key 'masks'\n",
        "    np.savez_compressed(OUTPUT_NPZ_PATH, masks=final_masks_array)\n",
        "\n",
        "    print(f\"SUCCESS: {OUTPUT_NPZ_PATH} created. This file is now small enough for GitHub. DOWNLOAD AND REPLACE.\")\n",
        "else:\n",
        "    print(\"ERROR: No frames processed. Check video path.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
